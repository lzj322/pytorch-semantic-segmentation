{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from math import sqrt\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.transforms as standard_transforms\n",
    "import torchvision.utils as vutils\n",
    "from tensorboard import SummaryWriter\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils.joint_transforms as joint_transforms\n",
    "import utils.transforms as extended_transforms\n",
    "from datasets import LIP\n",
    "from models import *\n",
    "from utils import check_mkdir, evaluate, AverageMeter, CrossEntropyLoss2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ckpt_path = './checkpoints/'\n",
    "exp_name = 'lip-psp_net'\n",
    "writer = SummaryWriter(os.path.join(ckpt_path, 'exp', exp_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'train_batch_size': 8,\n",
    "    'lr': 1e-2 / sqrt(16. / 4),\n",
    "    'lr_decay': 0.9,\n",
    "    'max_iter': 3e4,\n",
    "    'longer_size': 512,\n",
    "    'crop_size': 473,\n",
    "    'stride_rate': 2 / 3.,\n",
    "    'weight_decay': 1e-4,\n",
    "    'momentum': 0.9,\n",
    "    'snapshot': '',\n",
    "    'print_freq': 10,\n",
    "    'val_save_to_img_file': True,\n",
    "    'val_img_sample_rate': 0.01,  # randomly sample some validation results to display,\n",
    "    'val_img_display_size': 384,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_joint_transform = joint_transforms.Compose([\n",
    "    joint_transforms.RandomSized(args['crop_size']),\n",
    "    # joint_transforms.Scale(args['longer_size']),\n",
    "    joint_transforms.RandomRotate(10),\n",
    "    joint_transforms.RandomHorizontallyFlip()\n",
    "])\n",
    "sliding_crop = joint_transforms.SlidingCrop(args['crop_size'], args['stride_rate'], LIP.ignore_label)\n",
    "train_input_transform = standard_transforms.Compose([\n",
    "    standard_transforms.ToTensor(),\n",
    "    standard_transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_input_transform = standard_transforms.Compose([\n",
    "    standard_transforms.ToTensor(),\n",
    "    standard_transforms.Normalize(*mean_std)\n",
    "])\n",
    "target_transform = extended_transforms.MaskToTensor()\n",
    "visualize = standard_transforms.Compose([\n",
    "    standard_transforms.Scale(args['val_img_display_size']),\n",
    "    standard_transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = LIP.LIP('train', joint_transform=train_joint_transform,\n",
    "                                      transform=train_input_transform, target_transform=target_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=args['train_batch_size'], num_workers=8, shuffle=False)\n",
    "val_set = LIP.LIP('val', transform=val_input_transform,\n",
    "                                target_transform=target_transform)\n",
    "val_loader = DataLoader(val_set, batch_size=1, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _PyramidPoolingModule(nn.Module):\n",
    "    def __init__(self, in_dim, reduction_dim, setting):\n",
    "        super(_PyramidPoolingModule, self).__init__()\n",
    "        self.features = []\n",
    "        for s in setting:\n",
    "            self.features.append(nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(s),\n",
    "                nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(reduction_dim, momentum=.95),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        self.features = nn.ModuleList(self.features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        out = [x]\n",
    "        for f in self.features:\n",
    "            out.append(F.upsample(f(x), x_size[2:], mode='bilinear'))\n",
    "        out = torch.cat(out, 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True, use_aux=True):\n",
    "        super(PSPNet, self).__init__()\n",
    "        self.use_aux = use_aux\n",
    "        resnet = models.resnet101()\n",
    "        if pretrained:\n",
    "            resnet.load_state_dict(torch.load(res101_path))\n",
    "        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)\n",
    "        self.layer1, self.layer2, self.layer3, self.layer4 = resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
    "\n",
    "        for n, m in self.layer3.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "        for n, m in self.layer4.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "\n",
    "        self.ppm = _PyramidPoolingModule(2048, 512, (1, 2, 3, 6))\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(4096, 512, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512, momentum=.95),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        if use_aux:\n",
    "            self.aux_logits = nn.Conv2d(1024, num_classes, kernel_size=1)\n",
    "            initialize_weights(self.aux_logits)\n",
    "\n",
    "        initialize_weights(self.ppm, self.final)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        if self.training and self.use_aux:\n",
    "            aux = self.aux_logits(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.ppm(x)\n",
    "        x = self.final(x)\n",
    "        if self.training and self.use_aux:\n",
    "            return F.upsample(x, x_size[2:], mode='bilinear'), F.upsample(aux, x_size[2:], mode='bilinear')\n",
    "        return F.upsample(x, x_size[2:], mode='bilinear')\n",
    "\n",
    "\n",
    "# just a try, not recommend to use\n",
    "class PSPNetDeform(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, pretrained=True, use_aux=True):\n",
    "        super(PSPNetDeform, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.use_aux = use_aux\n",
    "        resnet = models.resnet101()\n",
    "        if pretrained:\n",
    "            resnet.load_state_dict(torch.load(res101_path))\n",
    "        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "\n",
    "        for n, m in self.layer3.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.padding = (1, 1)\n",
    "                m.stride = (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "        for n, m in self.layer4.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.padding = (1, 1)\n",
    "                m.stride = (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "        for idx in range(len(self.layer3)):\n",
    "            self.layer3[idx].conv2 = Conv2dDeformable(self.layer3[idx].conv2)\n",
    "        for idx in range(len(self.layer4)):\n",
    "            self.layer4[idx].conv2 = Conv2dDeformable(self.layer4[idx].conv2)\n",
    "\n",
    "        self.ppm = _PyramidPoolingModule(2048, 512, (1, 2, 3, 6))\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(4096, 512, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512, momentum=.95),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        if use_aux:\n",
    "            self.aux_logits = nn.Conv2d(1024, num_classes, kernel_size=1)\n",
    "            initialize_weights(self.aux_logits)\n",
    "\n",
    "        initialize_weights(self.ppm, self.final)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        if self.training and self.use_aux:\n",
    "            aux = self.aux_logits(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.ppm(x)\n",
    "        x = self.final(x)\n",
    "        if self.training and self.use_aux:\n",
    "            return F.upsample(x, self.input_size, mode='bilinear'), F.upsample(aux, self.input_size, mode='bilinear')\n",
    "        return F.upsample(x, self.input_size, mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "data=dataiter.next()\n",
    "img,gts = dataiter.next()\n",
    "print(img.size(),gts.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net=PSPNet(num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n",
      "(torch.Size([8, 3, 473, 473]), torch.Size([8, 473, 473]))\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    for i,data in enumerate(train_loader):\n",
    "        inputs,gts = data\n",
    "        print(inputs.size(),gts.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "ssap_exp_config": {
   "error_alert": "Error Occurs!",
   "initial": [],
   "max_iteration": 1000,
   "recv_id": "",
   "running": [],
   "summary": [],
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
